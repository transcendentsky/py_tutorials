===> Loading data
[DEBUG] Dataset len: 16551
PYTORCH:DEBUG: INIT Dataloader
[DEBUG] Dataset len: 4952
PYTORCH:DEBUG: INIT Dataloader
===> Building model
==>Feature map size:
[(38L, 38L), (19L, 19L), (10L, 10L), (5L, 5L), (3L, 3L), (1L, 1L)]
Utilize GPUs for computation
Number of GPU available 1
Trainable scope: base,norm,extras,loc,conf
Loss Reduce Setting is: False
Checkpoint ./experiments/pre_test/resnet50_rfb_voc_81.2.pth:
=> loading checkpoint './experiments/pre_test/resnet50_rfb_voc_81.2.pth'
11620

===> Loading data
[DEBUG] Dataset len: 16551
PYTORCH:DEBUG: INIT Dataloader
[DEBUG] Dataset len: 4952
PYTORCH:DEBUG: INIT Dataloader
===> Building model
==>Feature map size:
[(38L, 38L), (19L, 19L), (10L, 10L), (5L, 5L), (3L, 3L), (1L, 1L)]
Utilize GPUs for computation
Number of GPU available 1
Trainable scope: base,norm,extras,loc,conf
Loss Reduce Setting is: False
Epoch 200/300:
=> loading checkpoint './experiments/models/mixup/rfb_resnet50_voc/rfb_resnet_50_voc_epoch_200.pth'
./experiments/models/mixup/rfb_resnet50_voc/rfb_resnet_50_voc_epoch_200.pth
11620


(0.024693012237548828, 0.014788228643704071, 0.00030224890935988657, 0.00023879153387887137, 0.021149430388496038)
(0.0497589111328125, 0.013883799748227704, 0.00010722497152903723, 0.00020761631783984956, 0.04209484003839039)
(0.04835391044616699, 0.016661343648171404, 8.996857537163627e-05, 0.00017690308510311066, 0.047722312949952626)
(0.03177595138549805, 0.017246597809213827, 7.460912068684896e-05, 0.00014201686495826359, 0.019107965060642787)
(0.050956010818481445, 0.01713827175098481, 8.746754555475143e-05, 0.00016535520553588866, 0.03928539071764265)
(0.027225971221923828, 0.016493479289560197, 5.463759104410807e-05, 0.0001044313112894694, 0.022990087668100994)



(0.14493393898010254, 0.01448027040356643, 0.0004554503545794859, 0.000499885533602464, 0.14673999209072197)
(0.16930890083312988, 0.007331245052568834, 0.00020688810790531613, 0.0004016134405014421, 0.15889482323788343)
(0.1524949073791504, 0.009590039282663906, 0.0002053834386563204, 0.0004002655962465965, 0.15424904107981302)
(0.17087221145629883, 0.009740039591852158, 0.00020774426552845122, 0.0004041543505136447, 0.1752373545456047)
